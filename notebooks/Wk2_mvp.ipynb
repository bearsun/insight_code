{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = '../data/nba_reg18/'\n",
    "\n",
    "ds_sub = pd.DataFrame()\n",
    "ds_com = pd.DataFrame()\n",
    "\n",
    "nf_subs = 7 #7 files for submissions\n",
    "nf_coms = 12 #12 files for comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for icom in range(1, nf_subs+1):\n",
    "    path_ds = dir_data + 'nba_submissions_reg18_' + str(icom) + '.csv'\n",
    "    ds_cur = pd.read_csv(path_ds, index_col = 0, parse_dates = ['created'])\n",
    "    ds_sub = ds_sub.append(ds_cur).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for icom in range(1, nf_coms+1):\n",
    "    path_ds = dir_data + 'nba_comments_reg18_' + str(icom) + '.csv'\n",
    "    ds_cur = pd.read_csv(path_ds, index_col = 0, parse_dates = ['created'])\n",
    "    ds_com = ds_com.append(ds_cur).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92383, 6)\n",
      "(2064767, 6)\n"
     ]
    }
   ],
   "source": [
    "print(ds_sub.shape)\n",
    "print(ds_com.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standerdize Team Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_names = pd.read_csv('teams', names = ['name', 'abbrs'])\n",
    "team_dict = team_names.set_index('name').to_dict()['abbrs']\n",
    "team_fulls = team_names['name'].to_list()\n",
    "team_abbrs = team_names['abbrs'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flair2team(flair, team_dict, team_fulls, team_abbrs):\n",
    "    # transform all flairs (team names, player names with team abbrs) into team abbrs only\n",
    "    \n",
    "    # team names\n",
    "    for name in team_fulls:\n",
    "        if name in flair:\n",
    "            return team_dict[name]\n",
    "    \n",
    "    # player names with team abbrs\n",
    "    for abbr in team_abbrs:\n",
    "        if abbr in flair:\n",
    "            return abbr\n",
    "    \n",
    "    # otherwise return original (bind into \"others\" later)\n",
    "    return flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of the weired pandas float nan\n",
    "ds_com.loc[ds_com['flair'].isnull().values, 'flair'] = 'NONE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping to abbrev team name\n",
    "ds_com['flair'] = ds_com['flair'].apply(flair2team, args = [team_dict, team_fulls, team_abbrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. Total:\n",
      "(2064767, 6)\n",
      "No. for 31 Teams:\n",
      "(1562342, 6)\n"
     ]
    }
   ],
   "source": [
    "print('No. Total:')\n",
    "print(ds_com.shape)\n",
    "ds_com = ds_com.loc[ds_com['flair'].isin(team_abbrs), :]\n",
    "print('No. for 31 Teams:')\n",
    "print(ds_com.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the same for submissions\n",
    "# get rid of the weired pandas float nan\n",
    "ds_sub.loc[ds_sub['flair'].isnull().values, 'flair'] = 'NONE'\n",
    "ds_sub['flair'] = ds_sub['flair'].apply(flair2team, args = [team_dict, team_fulls, team_abbrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. Total:\n",
      "(92383, 6)\n",
      "No. for 31 Teams:\n",
      "(55475, 6)\n"
     ]
    }
   ],
   "source": [
    "print('No. Total:')\n",
    "print(ds_sub.shape)\n",
    "ds_sub = ds_sub.loc[ds_sub['flair'].isin(team_abbrs), :]\n",
    "print('No. for 31 Teams:')\n",
    "print(ds_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at comment/fan distribution\n",
    "#ds_comment_by_fan = ds_com.groupby(['author'])['author'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ds_comment_by_fan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ds_comment_by_fan.loc[ds_comment_by_fan < 50].hist(bins = 100, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ds_com.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#users = ds_com[['author', 'flair']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#users.groupby('flair')['author'].count().sort_values(ascending = False).plot.bar(figsize = (20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_sub_by_fan = ds_sub.groupby('author')['author'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_sub_by_fan.loc[ds_sub_by_fan<20].hist(bins = 100, figsize = (20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put submissions and comments together\n",
    "ds = pd.concat([ds_sub[['author', 'flair', 'title', 'created']].rename(columns = {'flair':'team', 'title':'text'}),\n",
    "                ds_com[['author', 'flair', 'text', 'created']].rename(columns = {'flair':'team'})],\n",
    "               ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1617817, 4)\n"
     ]
    }
   ],
   "source": [
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove links and emojis\n",
    "ds['text'] = ds['text'].map(lambda x: re.sub(r'((http|ftp|https):\\/\\/)?[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;:/~\\+#]*[\\w\\-\\@?^=%&amp;/~\\+#])?', ' ', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_punctuation(text):\n",
    "    #replace punctuation with space\n",
    "    no_punct = ''.join([c if c not in string.punctuation else ' ' for c in text])\n",
    "    #replace special char like ðŸ€\n",
    "    no_punct = no_punct.encode('ascii', 'ignore').decode('ascii')\n",
    "    #remove \\n \\t \\r\n",
    "    return no_punct.translate(str.maketrans(\"\\n\\t\\r\", \"   \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['text'] = ds['text'].apply(replace_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Game Time Data (who posted during a team's games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load game data\n",
    "gametime = pd.read_csv('../data/game_schedule_reg18.csv',\n",
    "                       names = ['date', 'time', 'visitor', 'vpts', 'home', 'hpts',\n",
    "                                  'box', 'ot', 'attend', 'notes'],\n",
    "                      skiprows=1).drop(['box', 'notes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine date&time to datetime\n",
    "form = '%a %b %d %Y %I:%M%p'\n",
    "def dataplustime(ds):\n",
    "    return datetime.strptime(ds['date'] + ' ' + ds['time'] + 'm', form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gametime['datetime'] = gametime[['date', 'time']].apply(dataplustime, axis=1)\n",
    "gametime.drop(['date', 'time'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add overtimes to game time (10 min extension per overtime)\n",
    "# get rid of the float nan\n",
    "gametime.loc[gametime['ot'].isnull(), 'ot'] = 'NAN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many OTs\n",
    "def count_ots(ot):\n",
    "    if ot == 'NAN':\n",
    "        return 0\n",
    "    elif ot == 'OT':\n",
    "        return 1\n",
    "    else:\n",
    "        return int(ot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gametime['ot'] = gametime['ot'].apply(count_ots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standerdize team name\n",
    "gametime['visitor'] = gametime['visitor'].apply(flair2team, args = [team_dict, team_fulls, team_abbrs])\n",
    "gametime['home'] = gametime['home'].apply(flair2team, args = [team_dict, team_fulls, team_abbrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat home/visitor games together\n",
    "tgame = pd.concat([gametime[['visitor', 'datetime', 'ot']].rename(columns = {'visitor':'team'}),\n",
    "                  gametime[['home', 'datetime', 'ot']].rename(columns = {'home':'team'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate end_time for games\n",
    "duration = 2.5 #2.5 hrs per game\n",
    "ot_duration = 10 #10 min per OT\n",
    "tgame['end_time'] = tgame['datetime'] + pd.Timedelta(duration, unit='h') + tgame['ot'].apply(lambda x: pd.Timedelta(x*ot_duration, unit='m'))\n",
    "tgame = tgame.rename(columns={'datetime':'start_time'}).drop('ot', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple (start_time, end_time)\n",
    "tgame['time_span'] = list(zip(tgame['start_time'], tgame['end_time']))\n",
    "# group by team, each team get a list of game time tuples\n",
    "ttgame = tgame.drop(['start_time', 'end_time'], axis=1).groupby('team')['time_span'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# go through the dataset, assign game time tags for each entry (posted during X team's games, 30 columns added)\n",
    "for team, time in ttgame.items():\n",
    "    ds[team] = 0\n",
    "    for ts, te in time:\n",
    "        ds.loc[(ds['created'] > ts) & (ds['created'] < te), team] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all texts by users\n",
    "ds_user = ds.groupby(['author', 'team'])['text'].apply(lambda x: ' '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_abbrs.remove('SEA')\n",
    "team_abbrs = list(set(team_abbrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count game posts\n",
    "game_posts = ds.drop(['team', 'text', 'created'], axis=1).groupby('author')[team_abbrs].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the count to each user's total count\n",
    "game_posts['total'] = game_posts.sum(axis=1)\n",
    "game_posts[team_abbrs] = game_posts[team_abbrs].div(game_posts['total'], axis=0)\n",
    "game_posts = game_posts.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach to user dataset\n",
    "ds_user = ds_user.set_index('author').join(game_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction using tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000, ngram_range=(1, 1), stop_words='english', max_df=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ds_user.drop(['team','total'], axis=1), ds_user['team'], test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = tfidf.fit_transform(X_train['text'])\n",
    "test_txt = tfidf.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54945, 1000)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_txt.A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = np.concatenate((train_txt.A, X_train.drop('text', axis=1).values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = np.concatenate((test_txt.A, X_test.drop('text', axis=1).values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_nb = MultinomialNB()\n",
    "tfidf_nb.fit(train_all, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2880698880698881"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_nb.score(train_all, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.278663463638349"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_nb.score(test_all, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_nb = MultinomialNB()\n",
    "tfidf_nb.fit(train_txt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28382928382928385"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_nb.score(train_txt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27407730945621317"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_nb.score(test_txt, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_base = ds['team'].to_frame()\n",
    "ds_base['pred'] = ds_base['team'].sample(frac=1, random_state=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_base['team'] == ds_base['pred']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = cvec_nb.predict_proba(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "y_test_ohe = enc.fit_transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_nb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = ds_base['team'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_ohe = y_test_ohe.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_ohe[:, i], y_test_prob[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_ohe.ravel(), y_test_prob.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
